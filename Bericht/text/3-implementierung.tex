\section{Implementierung und praktische Details}
\label{chap:implementierung}

Dieses Kapitel gibt einen kurzen Überblick zu den von uns verwendeten Technologien, die wir zur Realisierung des theoretischen Entwurfs aus Kapitel \ref{chap:entwurf} verwendet haben.


\subsection{Videomaterial}
\label{sec:videomat}

Das uns zur Verfügung gestellte Bildmaterial besteht aus einzelnen Videosequenzen, wir können also nicht auf Live-Material arbeiten.\\

In der Praxis spielt dies jedoch keine große Rolle, da unter Linux der Zugriff auf eine Videodatei sich nicht wesentlich von dem Zugriff auf eine Kamera unterscheidet.
Insgesamt standen uns sieben unterschiedliche Videosequenzen zur Verfügung, von denen sechs paarweise entstandene Aufnahmen sind.
 Das bedeutet, dass Kameraposition sowie Winkel zwischen den beiden Videosequenzen eines Paares nicht differiert, lediglich die aufgenommenen Szenen sind unterschiedlich.
 Diese Tatsache ist insofern hilfreich, als das wir die Möglichkeit haben, auf einer Videosequenz zu lernen und die erlernten Parameter später auf der anderen Videosequenz anzuwenden.\\
Der größte Nachteil der Verwendung von Videosequenzen ist, dass die einzelnen Sequenzen relativ kurz sind (Dauer übersteigt nicht 10 Minuten) und es somit nicht möglich ist, wirklich lange Lernphasen von zum Beispiel einigen Stunden zu realisieren. Der Vorteil ist hingegen, dass man Veränderungen an Programmbestandteilen und Parametern immer wieder an den selben Sequenzen ausprobieren kann und somit den entstehenden Effekt besser nachvollziehen kann.\\
%TODO: Need Vorteil
Sämtliche Videosequenzen laufen mit 25 Frames pro Sekunde, was auf jeden Fall genug Daten zur Auswertung liefert.
 In der Praxis genügen vermutlich auch schon weniger Frames, da anhand der vorliegenden Videos deutlich wurde, dass sich die Personen im Bild nicht so schnell bewegen, dass sich innerhalb eines Bruchteils einer Sekunde die Szenerie stark verändert.

\subsection{C++}
\label{sec:cpp}
Die Implementierung sowohl unseres Testbeds als auch die finale Implementierung als Komponente zur Vordergrundextraktion in einem vorgegebenen Framework fand in C++ statt.
 Für die Wahl von C++ gab es verschiedene Gründe, von denen vor allem die Performance, die Portabilität sowie das gute Angebot an zur Verfügung stehenden Bibliotheken im Vordergrund standen.

\subsection{OpenCV}
\label{sec:opencv}
OpenCV ist eine Bibliothek die eine Vielzahl unterschiedlicher Algorithmen für die Bildbearbeitung und somit letztlich für die Videobearbeitung zur Verfügung stellt.
 Hinzu kommt, dass auch Funktionen für das Lesen, Schreiben und Abspielen von Videodateien verschiedener Datentypen sowie von Kamera angeboten werden. Videos und Bilder werden in das OpenCV spezifische Format Mat eingelesen, auf dem viele Operationen möglich sind.  Die von uns vorgestellte DCT ist Teil dieser Bibliothek und konnte von uns direkt auf den Mat-Objekten angewandt werden.\\
OpenCV bietet Interfaces für C, Python, Java und C++ und lässt sich auf vielen unterschiedlichen Plattformen einsetzen.


\subsection{CvHMM}
\label{sec:cvhmm}
Aus der Menge der vorhandenen C++-HMM Bibliotheken fiel unsere Wahl auf CvHMM\cite{cvhmmLINK}, vor allem da diese Bibliothek direkt auf dem in OpenCV enthaltenen Standard-Videodatentyp Mat operiert und daher die Vermutung nahe liegt, dass weniger Performanceeinbußen vorliegen, da keine Konvertierung von Daten in andere Formate erfolgen muss.\\


